{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "homography_intro",
   "metadata": {},
   "source": [
    "# üí° Homography and Perspective Transform in OpenCV\n",
    "\n",
    "Welcome to a **comprehensive guide** on Homography and Perspective Transformation in OpenCV.\n",
    "This notebook is structured to take you from a beginner to an advanced OpenCV user.\n",
    "\n",
    "### What you will learn:\n",
    "- How Homography works mathematically\n",
    "- How to compute homography matrices using OpenCV\n",
    "- How to perform perspective warping on images\n",
    "- How to handle noisy or imperfect correspondences using RANSAC\n",
    "- Real-world use cases like document scanning, AR, and image stitching\n",
    "\n",
    "Homography allows you to **map points from one plane to another**, which is more general than affine transformations. It preserves lines but can handle perspective distortions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "math_intuition",
   "metadata": {},
   "source": [
    "## üîπ Mathematical Intuition\n",
    "\n",
    "The homography matrix `H` is a 3x3 matrix that transforms a point `(x, y)` in the source image to `(x', y')` in the destination image:\n",
    "\n",
    "$$ \\begin{bmatrix} x' \\\\ y' \\\\ w' \\end{bmatrix} = H \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}, \\quad H = \\begin{bmatrix} h_{11} & h_{12} & h_{13} \\\\ h_{21} & h_{22} & h_{23} \\\\ h_{31} & h_{32} & 1 \\end{bmatrix} $$\n",
    "\n",
    "After dividing by `w'`:\n",
    "$$ x' = x'/w', \\quad y' = y'/w' $$\n",
    "\n",
    "- Homography is **projective**: it can handle perspective effects.\n",
    "- Affine is a special case (last row `[0, 0, 1]`).\n",
    "- We need at least **4 point correspondences** to solve for H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Setup\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tools.tools import LearnTools\n",
    "\n",
    "learn_tools = LearnTools()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_image",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "# img_url = \"https://i.ibb.co/5x276TvQ/1.jpg\"\n",
    "# img_url = \"https://i.ibb.co/QjkCQ6Vm/2.jpg\"\n",
    "img_url = \"https://i.ibb.co/NyT8LB5/test.jpg\"\n",
    "\n",
    "\n",
    "if os.path.exists('testImage.jpg'):\n",
    "    image = cv2.imread('testImage.jpg')\n",
    "else:\n",
    "    pil_image = await learn_tools.get_image(img_url=img_url, padding=0)\n",
    "    pil_image.save('testImage.jpg', 'JPEG')\n",
    "    image = learn_tools.pil_to_cv2(pil_image)\n",
    "\n",
    "learn_tools.show_multiple_images(\n",
    "        image_plotting_data=[\n",
    "            {'title': 'Original Image', 'image': image}\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "define_points",
   "metadata": {},
   "source": [
    "## üîπ Define Corresponding Points\n",
    "\n",
    "To compute homography, select **at least 4 points** in the source image and their corresponding positions in the destination plane.\n",
    "\n",
    "Tips:\n",
    "- Choose points that are spread across the image.\n",
    "- Avoid points that are too close to each other.\n",
    "- For interactive selection, OpenCV's `cv2.setMouseCallback` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "points_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = image.shape[:2]\n",
    "\n",
    "# Source points in clockwise order (top-left, top-right, bottom-right, bottom-left)\n",
    "pts_src = np.float32([[50, 50], [200, 50], [200, 200], [50, 200]])\n",
    "\n",
    "# Destination points simulating a perspective transform\n",
    "pts_dst = np.float32([[10, 100], [220, 50], [210, 210], [30, 220]])\n",
    "\n",
    "# Visualize source points\n",
    "img_vis = image.copy()\n",
    "for pt in pts_src:\n",
    "    cv2.circle(img_vis, tuple(pt.astype(int)), 6, (0,0,255), -1)\n",
    "learn_tools.show_multiple_images([\n",
    "    {'title': 'Original Image with Source Points', 'image': img_vis}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compute_homography",
   "metadata": {},
   "source": [
    "## üîπ Compute Homography\n",
    "\n",
    "Use `cv2.findHomography` to compute the 3x3 matrix `H`:\n",
    "\n",
    "- The function can also use **RANSAC** to handle noisy points.\n",
    "- `status` shows which points were considered inliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homography_compute",
   "metadata": {},
   "outputs": [],
   "source": [
    "H, status = cv2.findHomography(pts_src, pts_dst)\n",
    "print(\"Homography Matrix:\\n\", H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warp_perspective",
   "metadata": {},
   "source": [
    "## üîπ Apply Perspective Transform\n",
    "\n",
    "Use `cv2.warpPerspective` to apply the homography matrix to the entire image:\n",
    "\n",
    "- This maps the original image onto the new plane defined by `pts_dst`.\n",
    "- The size `(cols, rows)` ensures the output image has the same dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warp_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.warpPerspective(image, H, (cols, rows))\n",
    "learn_tools.show_multiple_images([\n",
    "    {'title': 'Original Image', 'image': image},\n",
    "    {'title': 'Warped Image', 'image': dst}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ransac_explanation",
   "metadata": {},
   "source": [
    "## üîπ Robust Homography with RANSAC\n",
    "\n",
    "In real-world scenarios, point correspondences may have noise. **RANSAC** helps compute a robust homography:\n",
    "\n",
    "- It iteratively selects random subsets of points.\n",
    "- Finds the homography that maximizes the number of inliers.\n",
    "- Minimizes the effect of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ransac_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_ransac, status_ransac = cv2.findHomography(pts_src, pts_dst, cv2.RANSAC)\n",
    "dst_ransac = cv2.warpPerspective(image, H_ransac, (cols, rows))\n",
    "learn_tools.show_multiple_images([\n",
    "    {'title': 'Warped Image with RANSAC', 'image': dst_ransac}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "real_world_use_cases",
   "metadata": {},
   "source": [
    "## üåç Real-World Use Cases\n",
    "- **Document Scanning**: Correct skewed documents automatically.\n",
    "- **Image Stitching**: Align overlapping photos to create panoramas.\n",
    "- **Augmented Reality**: Map virtual objects onto planar surfaces.\n",
    "- **Object Tracking**: Track planar objects under perspective changes.\n",
    "- **Video Stabilization**: Align frames to reduce camera shake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best_practices",
   "metadata": {},
   "source": [
    "## ‚úÖ Best Practices and Tips\n",
    "- Use **at least 4 widely spread points** to ensure a stable solution.\n",
    "- Always visualize points before and after transformation.\n",
    "- Use `cv2.RANSAC` for robustness against incorrect correspondences.\n",
    "- For **image stitching**, blend overlapping areas to remove seams.\n",
    "- Combine homography with other transformations (affine, scaling) for complex pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee0c85",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8755cea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9843a827",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb65c25f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15335adf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "057c22dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c99d6d11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "296ad5ad",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
