{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "math_intuition",
   "metadata": {},
   "source": [
    "# ðŸ’¡ Homography and Perspective Transform in OpenCV\n",
    "\n",
    "`Homography` allows you to **map points from one plane to another**, which is more general than `affine transformations`. It preserves lines but can handle perspective distortions.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Mathematical Intuition\n",
    "\n",
    "The homography matrix `H` is a 3x3 matrix that transforms a point `(x, y)` in the source image to `(x', y')` in the destination image:\n",
    "\n",
    "$$ \\begin{bmatrix} x' \\\\ y' \\\\ w' \\end{bmatrix} = H \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}, \\quad H = \\begin{bmatrix} h_{11} & h_{12} & h_{13} \\\\ h_{21} & h_{22} & h_{23} \\\\ h_{31} & h_{32} & 1 \\end{bmatrix} $$\n",
    "\n",
    "After dividing by `w'`:\n",
    "$$ x' = x'/w', \\quad y' = y'/w' $$\n",
    "\n",
    "- Homography is `projective`, it can handle perspective effects.\n",
    "- Affine is a special case (last row `[0, 0, 1]`).\n",
    "- We need at least `4 point correspondences` to solve for H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Setup\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tools.tools import LearnTools\n",
    "\n",
    "learn_tools = LearnTools()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_image",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "# img_url = \"https://i.ibb.co/5x276TvQ/1.jpg\"\n",
    "# img_url = \"https://i.ibb.co/QjkCQ6Vm/2.jpg\"\n",
    "# img_url = \"https://i.ibb.co/NyT8LB5/test.jpg\"\n",
    "img_url = \"https://i.ibb.co.com/Pv7CFM89/196ef9c8-fe1c-4a13-8774-6078761fd220.jpg\"\n",
    "\n",
    "\n",
    "if os.path.exists('testImage.jpg'):\n",
    "    image = cv2.imread('testImage.jpg')\n",
    "else:\n",
    "    pil_image = await learn_tools.get_image(img_url=img_url, padding=0)\n",
    "    pil_image.save('testImage.jpg', 'JPEG')\n",
    "    image = learn_tools.pil_to_cv2(pil_image)\n",
    "\n",
    "# Display Rsult\n",
    "learn_tools.show_multiple_images(\n",
    "        image_plotting_data=[\n",
    "            {'title': 'Original Image', 'image': image}\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "define_points",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Define Corresponding Points\n",
    "\n",
    "To compute a `homography`, you must provide at least 4 pairs of corresponding points between:\n",
    "- The source image (`input perspective`)\n",
    "- The destination plane (`rectified or target perspective`)\n",
    "\n",
    "**Best practices:**\n",
    "- Points must be geometrically consistent (same physical corners).\n",
    "- Distribute points across the full object/region, not clustered.\n",
    "- Avoid nearly collinear points â€” homography becomes unstable.\n",
    "- Ensure a consistent order (e.g., top-left â†’ top-right â†’ bottom-right â†’ bottom-left).\n",
    "\n",
    "**For interactive point selection, OpenCVâ€™s `cv2.setMouseCallback` can be used to collect coordinates directly from the image.**\n",
    "\n",
    "## ðŸ”¹ Compute Homography\n",
    "Use `cv2.findHomography()` to estimate the 3Ã—3 projective transformation matrix `H`:\n",
    "- With exact, manually selected points, a direct solution is sufficient.\n",
    "- With noisy or automatically detected correspondences, enable `RANSAC` to:\n",
    "    - Reject outliers\n",
    "    - Improve robustness\n",
    "    - Identify inliers via the returned status mask\n",
    "\n",
    "`H, status = cv2.findHomography(src_points, dst_points, cv2.RANSAC, 3.0)`\n",
    "- `H` â†’ homography matrix\n",
    "- `status` â†’ binary mask indicating inlier correspondences\n",
    "\n",
    "## ðŸ”¹ Apply Perspective Transform\n",
    "\n",
    "Apply the homography to the entire image using `cv2.warpPerspective`:\n",
    "- This maps the source image onto the destination plane defined by `poimnts_destination`.\n",
    "- The output size must match the destination geometry, not the original image size.\n",
    "\n",
    "`warped = cv2.warpPerspective(image, H, (dst_width, dst_height))`\n",
    "- Using (`column`, `row`) is only correct if you explicitly want the original image dimensions.\n",
    "- For document rectification or top-down views, always use the computed destination width and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecbcd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "row, column = image.shape[:2]        # original image dimensions\n",
    "\n",
    "points_source = np.float32([\n",
    "    [25, 185],   # Top-left\n",
    "    [152, 194],  # Top-right\n",
    "    [142, 328],  # Bottom-right\n",
    "    [20, 290]    # Bottom-left\n",
    "])\n",
    "\n",
    "# Width\n",
    "width_top = np.linalg.norm(points_source[1] - points_source[0])\n",
    "width_bottom = np.linalg.norm(points_source[2] - points_source[3])\n",
    "max_width = int(max(width_top, width_bottom))\n",
    "\n",
    "# Height\n",
    "height_left = np.linalg.norm(points_source[3] - points_source[0])\n",
    "height_right = np.linalg.norm(points_source[2] - points_source[1])\n",
    "max_height = int(max(height_left, height_right))\n",
    "\n",
    "\n",
    "points_destination = np.float32([\n",
    "    [0, 0],\n",
    "    [max_width - 1, 0],\n",
    "    [max_width - 1, max_height - 1],\n",
    "    [0, max_height - 1]\n",
    "])\n",
    "\n",
    "\n",
    "M = cv2.getPerspectiveTransform(points_source, points_destination)\n",
    "warped = cv2.warpPerspective(image, M, (max_width, max_height))\n",
    "\n",
    "\n",
    "img_vis = image.copy()\n",
    "for pt in points_source:\n",
    "    cv2.circle(img_vis, tuple(pt.astype(int)), 6, (0, 0, 255), -1)\n",
    "\n",
    "learn_tools.show_multiple_images([\n",
    "    {'title': 'Original Image with Source Points', 'image': img_vis},\n",
    "    {'title': 'Perspective Corrected Output', 'image': warped}\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ransac_explanation",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Robust Homography with RANSAC\n",
    "\n",
    "In real-world scenarios, point correspondences may have noise. **RANSAC** helps compute a robust homography:\n",
    "\n",
    "- It iteratively selects random subsets of points.\n",
    "- Finds the homography that maximizes the number of inliers.\n",
    "- Minimizes the effect of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ransac_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_ransac, status_ransac = cv2.findHomography(\n",
    "    points_source,\n",
    "    points_destination,\n",
    "    cv2.RANSAC,\n",
    "    ransacReprojThreshold=3.0\n",
    ")\n",
    "\n",
    "# Safety check\n",
    "if H_ransac is None:\n",
    "    raise RuntimeError(\"Homography computation failed\")\n",
    "\n",
    "# Warp using destination size (NOT original image size)\n",
    "warped_ransac = cv2.warpPerspective(\n",
    "    image,\n",
    "    H_ransac,\n",
    "    (max_width, max_height)\n",
    ")\n",
    "\n",
    "\n",
    "learn_tools.show_multiple_images([\n",
    "    {'title': 'Perspective Corrected (RANSAC)', 'image': warped_ransac}\n",
    "])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
